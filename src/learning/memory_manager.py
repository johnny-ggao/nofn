"""
è®°å¿†ç®¡ç†å™¨ï¼ˆSQLite ç‰ˆæœ¬ï¼‰

å­˜å‚¨å’Œæ£€ç´¢äº¤æ˜“æ¡ˆä¾‹ï¼Œä½¿ç”¨åˆ†å±‚è®°å¿†æ¶æ„ï¼š
- çŸ­æœŸè®°å¿†ï¼ˆ7å¤©ï¼‰ï¼šè¯¦ç»†æ¡ˆä¾‹
- ä¸­æœŸè®°å¿†ï¼ˆå‘¨ï¼‰ï¼šæ‘˜è¦
- é•¿æœŸè®°å¿†ï¼ˆæœˆï¼‰ï¼šæ ¸å¿ƒç»éªŒ

ä½¿ç”¨ SQLite æ•°æ®åº“è¿›è¡ŒæŒä¹…åŒ–å­˜å‚¨
"""
import sqlite3
import json
import time
import random
from typing import List, Optional, Dict, Any
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
import threading

from numpy import floating


@dataclass
class TradingCase:
    """äº¤æ˜“æ¡ˆä¾‹"""
    # å¸‚åœºæ¡ä»¶
    market_conditions: dict  # å½“æ—¶çš„å¸‚åœºå¿«ç…§

    # å†³ç­–
    decision: str  # å½“æ—¶çš„å†³ç­–ï¼ˆLLMåˆ†ææ–‡æœ¬ï¼‰

    # æ‰§è¡Œç»“æœ
    execution_result: Optional[List[dict]] = None  # æ‰§è¡Œç»“æœ
    realized_pnl: Optional[float] = None  # å·²å®ç°ç›ˆäº

    # åæ€
    reflection: Optional[str] = None  # LLMçš„åæ€
    lessons_learned: Optional[List[str]] = None  # å­¦åˆ°çš„ç»éªŒ

    # å…ƒæ•°æ®
    timestamp: datetime = None
    case_id: Optional[str] = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()
        if self.case_id is None:
            self.case_id = f"case_{int(self.timestamp.timestamp())}"

    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        data['timestamp'] = self.timestamp.isoformat()
        return data

    @classmethod
    def from_dict(cls, data: dict) -> 'TradingCase':
        """ä»å­—å…¸åˆ›å»º"""
        if isinstance(data['timestamp'], str):
            data['timestamp'] = datetime.fromisoformat(data['timestamp'])
        return cls(**data)


@dataclass
class MemorySummary:
    """è®°å¿†æ‘˜è¦"""
    # æ—¶é—´èŒƒå›´
    period_start: datetime
    period_end: datetime
    period_type: str  # 'weekly' æˆ– 'monthly'

    # ç»Ÿè®¡æ•°æ®
    total_cases: int
    total_trades: int
    win_rate: float
    avg_pnl: float
    sharpe_ratio: float

    # å…³é”®æ¨¡å¼ï¼ˆLLMç”Ÿæˆï¼‰
    key_patterns: List[str]  # å‘ç°çš„äº¤æ˜“æ¨¡å¼
    successful_strategies: List[str]  # æˆåŠŸçš„ç­–ç•¥
    failed_strategies: List[str]  # å¤±è´¥çš„ç­–ç•¥

    # æ ¸å¿ƒç»éªŒ
    lessons: List[str]  # æç‚¼çš„ç»éªŒæ•™è®­

    # å¸‚åœºæ´å¯Ÿ
    market_insights: str  # LLMæ€»ç»“çš„å¸‚åœºçŠ¶æ€

    # å…ƒæ•°æ®
    summary_id: str = None
    created_at: datetime = None

    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
        if self.summary_id is None:
            period_key = self.period_start.strftime("%Y%m%d")
            self.summary_id = f"{self.period_type}_{period_key}"

    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        data['period_start'] = self.period_start.isoformat()
        data['period_end'] = self.period_end.isoformat()
        data['created_at'] = self.created_at.isoformat()
        return data

    @classmethod
    def from_dict(cls, data: dict) -> 'MemorySummary':
        """ä»å­—å…¸åˆ›å»º"""
        if isinstance(data['period_start'], str):
            data['period_start'] = datetime.fromisoformat(data['period_start'])
        if isinstance(data['period_end'], str):
            data['period_end'] = datetime.fromisoformat(data['period_end'])
        if isinstance(data['created_at'], str):
            data['created_at'] = datetime.fromisoformat(data['created_at'])
        return cls(**data)


class MemoryManager:
    """
    è®°å¿†ç®¡ç†å™¨ï¼ˆä½¿ç”¨ SQLiteï¼‰

    èŒè´£:
    1. å­˜å‚¨äº¤æ˜“æ¡ˆä¾‹
    2. æ£€ç´¢ç›¸å…³æ¡ˆä¾‹
    3. åˆ†ææˆåŠŸ/å¤±è´¥æ¨¡å¼
    4. æŒä¹…åŒ–åˆ° SQLite æ•°æ®åº“
    5. ç”Ÿæˆå’Œå­˜å‚¨è®°å¿†æ‘˜è¦
    """

    def __init__(self, db_path: str = "data/memory.db", llm=None):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        self._local = threading.local()
        self.llm = llm  # LLMç”¨äºç”Ÿæˆæ‘˜è¦

        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()

        # åŠ è½½ç»Ÿè®¡ä¿¡æ¯
        stats = self._get_db_stats()
        print(f"âœ… åŠ è½½äº† {stats['cases_count']} ä¸ªå†å²æ¡ˆä¾‹, {stats['summaries_count']} ä¸ªæ‘˜è¦")

    def _get_connection(self) -> sqlite3.Connection:
        """è·å–çº¿ç¨‹æœ¬åœ°çš„æ•°æ®åº“è¿æ¥"""
        if not hasattr(self._local, 'conn'):
            # å¢åŠ  timeout åˆ° 30 ç§’ä»¥å¤„ç†å¹¶å‘è®¿é—®
            self._local.conn = sqlite3.connect(
                str(self.db_path),
                timeout=30.0,
                check_same_thread=False
            )
            self._local.conn.row_factory = sqlite3.Row

            # å¯ç”¨ WAL æ¨¡å¼ä»¥æ”¯æŒå¹¶å‘è¯»å†™
            self._local.conn.execute('PRAGMA journal_mode=WAL')
            self._local.conn.execute('PRAGMA busy_timeout=30000')  # 30ç§’

        return self._local.conn

    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        conn = self._get_connection()
        cursor = conn.cursor()

        # åˆ›å»ºäº¤æ˜“æ¡ˆä¾‹è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS trading_cases (
                case_id TEXT PRIMARY KEY,
                timestamp TEXT NOT NULL,
                market_conditions TEXT NOT NULL,
                decision TEXT NOT NULL,
                execution_result TEXT,
                realized_pnl REAL,
                reflection TEXT,
                lessons_learned TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_cases_timestamp ON trading_cases(timestamp DESC)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_cases_realized_pnl ON trading_cases(realized_pnl)')

        # åˆ›å»ºè®°å¿†æ‘˜è¦è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS memory_summaries (
                summary_id TEXT PRIMARY KEY,
                period_start TEXT NOT NULL,
                period_end TEXT NOT NULL,
                period_type TEXT NOT NULL,
                total_cases INTEGER NOT NULL,
                total_trades INTEGER NOT NULL,
                win_rate REAL NOT NULL,
                avg_pnl REAL NOT NULL,
                sharpe_ratio REAL NOT NULL,
                key_patterns TEXT NOT NULL,
                successful_strategies TEXT NOT NULL,
                failed_strategies TEXT NOT NULL,
                lessons TEXT NOT NULL,
                market_insights TEXT NOT NULL,
                created_at TEXT NOT NULL
            )
        ''')

        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_summaries_period ON memory_summaries(period_start DESC)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_summaries_type ON memory_summaries(period_type)')

        conn.commit()

    def _get_db_stats(self) -> dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        conn = self._get_connection()
        cursor = conn.cursor()

        cursor.execute('SELECT COUNT(*) FROM trading_cases')
        cases_count = cursor.fetchone()[0]

        cursor.execute('SELECT COUNT(*) FROM memory_summaries')
        summaries_count = cursor.fetchone()[0]

        return {
            'cases_count': cases_count,
            'summaries_count': summaries_count
        }

    def add_case(self, case: TradingCase):
        """æ·»åŠ äº¤æ˜“æ¡ˆä¾‹ï¼ˆå¸¦å¼ºåŒ–é‡è¯•æœºåˆ¶ï¼‰"""
        max_retries = 10  # å¢åŠ åˆ°10æ¬¡
        base_delay = 0.5  # åŸºç¡€ç­‰å¾…500ms

        for attempt in range(max_retries):
            try:
                conn = self._get_connection()
                cursor = conn.cursor()

                cursor.execute('''
                    INSERT INTO trading_cases
                    (case_id, timestamp, market_conditions, decision, execution_result,
                     realized_pnl, reflection, lessons_learned)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    case.case_id,
                    case.timestamp.isoformat(),
                    json.dumps(case.market_conditions, ensure_ascii=False),
                    case.decision,
                    json.dumps(case.execution_result, ensure_ascii=False) if case.execution_result else None,
                    float(case.realized_pnl) if case.realized_pnl is not None else None,
                    case.reflection,
                    json.dumps(case.lessons_learned, ensure_ascii=False) if case.lessons_learned else None,
                ))

                conn.commit()

                # è‡ªåŠ¨æ¸…ç†æ—§æ¡ˆä¾‹ï¼ˆä¿ç•™æœ€è¿‘1000ä¸ªï¼‰
                self._cleanup_old_cases(max_cases=1000, keep_days=30)

                # æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                if attempt > 0:
                    print(f"âœ… æ¡ˆä¾‹ä¿å­˜æˆåŠŸï¼ˆé‡è¯• {attempt} æ¬¡åï¼‰")
                break

            except sqlite3.OperationalError as e:
                if "database is locked" in str(e) and attempt < max_retries - 1:
                    # è®¡ç®—å»¶è¿Ÿï¼šåŸºç¡€å»¶è¿Ÿ + æŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨
                    exponential_delay = base_delay * (1.5 ** attempt)
                    jitter = random.uniform(0, 0.3)  # éšæœºæŠ–åŠ¨0-300ms
                    retry_delay = exponential_delay + jitter

                    print(f"âš ï¸  æ•°æ®åº“é”å®šï¼Œ{retry_delay:.2f}ç§’åé‡è¯• ({attempt + 1}/{max_retries})...")
                    time.sleep(retry_delay)
                else:
                    # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥æˆ–å…¶ä»–é”™è¯¯ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    print(f"âŒ æ¡ˆä¾‹ä¿å­˜å¤±è´¥: é‡è¯• {max_retries} æ¬¡åä»ç„¶æ•°æ®åº“é”å®š")
                    raise

    def _cleanup_old_cases(self, max_cases: int = 1000, keep_days: int = 30):
        """
        æ¸…ç†æ—§æ¡ˆä¾‹

        ç­–ç•¥ï¼š
        1. ä¿ç•™æœ€è¿‘ keep_days å¤©çš„æ‰€æœ‰æ¡ˆä¾‹
        2. æ€»æ•°ä¸è¶…è¿‡ max_cases
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        # ç»Ÿè®¡æ€»æ•°
        cursor.execute('SELECT COUNT(*) FROM trading_cases')
        total_count = cursor.fetchone()[0]

        if total_count <= max_cases:
            return

        # ä¿ç•™æœ€è¿‘çš„ max_cases ä¸ªæ¡ˆä¾‹
        cutoff_date = (datetime.now() - timedelta(days=keep_days)).isoformat()

        cursor.execute('''
            DELETE FROM trading_cases
            WHERE case_id IN (
                SELECT case_id FROM trading_cases
                WHERE timestamp < ?
                ORDER BY timestamp DESC
                LIMIT -1 OFFSET ?
            )
        ''', (cutoff_date, max_cases))

        deleted = cursor.rowcount
        if deleted > 0:
            print(f"ğŸ“Š è®°å¿†æ¸…ç†: åˆ é™¤äº† {deleted} ä¸ªæ—§æ¡ˆä¾‹, ä¿ç•™æœ€è¿‘ {max_cases} ä¸ª")

        conn.commit()

    def get_recent_cases(self, days: int = 7, limit: Optional[int] = None) -> List[TradingCase]:
        """è·å–æœ€è¿‘Nå¤©çš„æ¡ˆä¾‹"""
        conn = self._get_connection()
        cursor = conn.cursor()

        cutoff = (datetime.now() - timedelta(days=days)).isoformat()

        query = '''
            SELECT * FROM trading_cases
            WHERE timestamp >= ?
            ORDER BY timestamp DESC
        '''

        if limit:
            query += f' LIMIT {limit}'

        cursor.execute(query, (cutoff,))

        return [self._row_to_case(row) for row in cursor.fetchall()]

    def search_similar(self, market_conditions: dict, k: int = 5) -> List[TradingCase]:
        """
        æ£€ç´¢ç›¸ä¼¼æ¡ˆä¾‹

        ç®€åŒ–ç‰ˆï¼šåŸºäºå¸‚åœºè¶‹åŠ¿ç›¸ä¼¼åº¦
        """
        # æå–å…³é”®ç‰¹å¾
        def extract_features(conditions: dict) -> dict:
            features = {}
            for symbol, asset in conditions.get('assets', {}).items():
                trend = asset.get('trend', {})
                features[symbol] = {
                    'trend_direction': trend.get('direction', 'neutral'),
                    'trend_strength': trend.get('strength', 50),
                }
            return features

        target_features = extract_features(market_conditions)

        # è·å–æ‰€æœ‰æ¡ˆä¾‹
        cases = self.get_recent_cases(days=30)  # åªæœç´¢æœ€è¿‘30å¤©

        # è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ’åº
        def similarity_score(case: TradingCase) -> float:
            case_features = extract_features(case.market_conditions)

            score = 0.0
            for symbol in target_features:
                if symbol in case_features:
                    # è¶‹åŠ¿æ–¹å‘åŒ¹é…
                    if target_features[symbol]['trend_direction'] == case_features[symbol]['trend_direction']:
                        score += 50

                    # è¶‹åŠ¿å¼ºåº¦ç›¸ä¼¼
                    strength_diff = abs(
                        target_features[symbol]['trend_strength'] - case_features[symbol]['trend_strength']
                    )
                    score += max(0, 50 - strength_diff)

            return score

        # æ’åºå¹¶è¿”å›top k
        scored_cases = [(case, similarity_score(case)) for case in cases]
        scored_cases.sort(key=lambda x: x[1], reverse=True)

        return [case for case, score in scored_cases[:k] if score > 0]

    def get_success_rate(self, conditions: Optional[dict] = None) -> float:
        """è®¡ç®—æˆåŠŸç‡"""
        if conditions:
            matching = self.search_similar(conditions, k=20)
        else:
            matching = self.get_recent_cases(days=30)

        if not matching:
            return 0.5  # é»˜è®¤50%

        successful = [
            case for case in matching
            if case.realized_pnl is not None and case.realized_pnl > 0
        ]

        return len(successful) / len(matching) if matching else 0.5

    def get_average_pnl(self, days: int = 7) -> float:
        """è®¡ç®—æœ€è¿‘Nå¤©çš„å¹³å‡ç›ˆäº"""
        recent = self.get_recent_cases(days)
        if not recent:
            return 0.0

        pnls = [case.realized_pnl for case in recent if case.realized_pnl is not None]
        return sum(pnls) / len(pnls) if pnls else 0.0

    def get_sharpe_ratio(self, days: int = 7) -> float | floating[Any]:
        """è®¡ç®—å¤æ™®æ¯”ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        recent = self.get_recent_cases(days)
        if not recent:
            return 0.0

        pnls = [case.realized_pnl for case in recent if case.realized_pnl is not None]
        if not pnls:
            return 0.0

        import numpy as np
        returns = np.array(pnls)
        if len(returns) < 2:
            return 0.0

        mean_return = np.mean(returns)
        std_return = np.std(returns)

        if std_return == 0:
            return 0.0

        # ç®€åŒ–çš„å¤æ™®æ¯”ç‡
        return mean_return / std_return

    def to_context(self, recent_days: int = 7, similar_cases: Optional[List[TradingCase]] = None) -> str:
        """
        ç”Ÿæˆè®°å¿†ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆä¾›LLMé˜…è¯»ï¼‰

        åŒ…æ‹¬ï¼š
        1. å†å²æ‘˜è¦ï¼ˆæ ¸å¿ƒç»éªŒï¼‰
        2. æœ€è¿‘è¡¨ç°ç»Ÿè®¡
        3. ç›¸ä¼¼æ¡ˆä¾‹
        """
        lines = ["## å†å²è®°å¿†", ""]

        # 1. æ·»åŠ å†å²æ‘˜è¦ï¼ˆæœ€é‡è¦çš„éƒ¨åˆ†ï¼‰
        summaries = self._get_recent_summaries(limit=2)
        if summaries:
            lines.append("### å†å²ç»éªŒæ€»ç»“")
            lines.append("")

            for summary in summaries:
                period_name = "æ¯å‘¨" if summary.period_type == 'weekly' else "æ¯æœˆ"
                lines.append(f"#### {period_name}æ‘˜è¦ ({summary.period_start.strftime('%Y-%m-%d')} - {summary.period_end.strftime('%Y-%m-%d')})")
                lines.append(f"- äº¤æ˜“: {summary.total_trades} æ¬¡, èƒœç‡ {summary.win_rate*100:.1f}%, å¤æ™® {summary.sharpe_ratio:.2f}")

                if summary.key_patterns:
                    lines.append("- **å…³é”®æ¨¡å¼**:")
                    for pattern in summary.key_patterns[:3]:
                        lines.append(f"  - {pattern}")

                if summary.successful_strategies:
                    lines.append("- **æˆåŠŸç­–ç•¥**:")
                    for strategy in summary.successful_strategies[:2]:
                        lines.append(f"  - {strategy}")

                if summary.lessons:
                    lines.append("- **æ ¸å¿ƒç»éªŒ**:")
                    for lesson in summary.lessons[:3]:
                        lines.append(f"  - {lesson}")

                lines.append("")

        # 2. æœ€è¿‘è¡¨ç°
        recent = self.get_recent_cases(recent_days)
        if recent:
            avg_pnl = self.get_average_pnl(recent_days)
            sharpe = self.get_sharpe_ratio(recent_days)
            success_rate = self.get_success_rate()

            lines.append(f"### æœ€è¿‘ {recent_days} å¤©è¡¨ç°")
            lines.append(f"- äº¤æ˜“æ¬¡æ•°: {len(recent)}")
            lines.append(f"- å¹³å‡ç›ˆäº: ${avg_pnl:.2f}")
            lines.append(f"- å¤æ™®æ¯”ç‡: {sharpe:.2f}")
            lines.append(f"- èƒœç‡: {success_rate * 100:.1f}%")
            lines.append("")

        # 3. ç›¸ä¼¼æ¡ˆä¾‹ï¼ˆå‡å°‘æ˜¾ç¤ºï¼Œå› ä¸ºæœ‰æ‘˜è¦äº†ï¼‰
        if similar_cases:
            lines.append("### ç›¸ä¼¼å†å²æ¡ˆä¾‹")
            for i, case in enumerate(similar_cases[:2], 1):  # åªæ˜¾ç¤ºå‰2ä¸ª
                lines.append(f"#### æ¡ˆä¾‹ {i}")
                lines.append(f"- æ—¶é—´: {case.timestamp.strftime('%Y-%m-%d %H:%M')}")
                if case.realized_pnl is not None:
                    result = "ç›ˆåˆ©" if case.realized_pnl > 0 else "äºæŸ"
                    lines.append(f"- ç»“æœ: {result} ${abs(case.realized_pnl):.2f}")
                if case.lessons_learned:
                    lines.append(f"- ç»éªŒ: {', '.join(case.lessons_learned[:2])}")
                lines.append("")

        return "\n".join(lines)

    def _get_recent_summaries(self, limit: int = 2) -> List[MemorySummary]:
        """è·å–æœ€è¿‘çš„æ‘˜è¦"""
        conn = self._get_connection()
        cursor = conn.cursor()

        cursor.execute('''
            SELECT * FROM memory_summaries
            ORDER BY period_start DESC
            LIMIT ?
        ''', (limit,))

        return [self._row_to_summary(row) for row in cursor.fetchall()]

    async def generate_weekly_summary(self, account_info: dict = None) -> Optional[MemorySummary]:
        """ç”Ÿæˆæ¯å‘¨æ‘˜è¦ï¼ˆå¯åŒ…å«è´¦æˆ·ä¿¡æ¯ï¼‰"""
        if not self.llm:
            return None

        # è·å–ä¸Šå‘¨çš„æ¡ˆä¾‹
        now = datetime.now()
        week_start = now - timedelta(days=7)

        conn = self._get_connection()
        cursor = conn.cursor()

        cursor.execute('''
            SELECT * FROM trading_cases
            WHERE timestamp >= ? AND timestamp <= ?
            ORDER BY timestamp DESC
        ''', (week_start.isoformat(), now.isoformat()))

        weekly_cases = [self._row_to_case(row) for row in cursor.fetchall()]

        if len(weekly_cases) < 5:  # æ¡ˆä¾‹å¤ªå°‘ï¼Œè·³è¿‡
            return None

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        stats = self._calculate_stats(weekly_cases)

        # LLM ç”Ÿæˆæ‘˜è¦ï¼ˆåŒ…å«è´¦æˆ·ä¿¡æ¯ï¼‰
        summary_text = await self._llm_summarize(weekly_cases, 'weekly', account_info)

        if not summary_text:
            return None

        # åˆ›å»ºæ‘˜è¦å¯¹è±¡
        summary = MemorySummary(
            period_start=week_start,
            period_end=now,
            period_type='weekly',
            **stats,
            **self._parse_summary_text(summary_text)
        )

        # ä¿å­˜æ‘˜è¦
        self._save_summary(summary)

        print(f"ğŸ“ ç”Ÿæˆæ¯å‘¨æ‘˜è¦: {len(weekly_cases)} ä¸ªæ¡ˆä¾‹ â†’ 1 ä¸ªæ‘˜è¦")

        return summary

    def _save_summary(self, summary: MemorySummary):
        """ä¿å­˜æ‘˜è¦åˆ°æ•°æ®åº“"""
        conn = self._get_connection()
        cursor = conn.cursor()

        cursor.execute('''
            INSERT OR REPLACE INTO memory_summaries
            (summary_id, period_start, period_end, period_type, total_cases, total_trades,
             win_rate, avg_pnl, sharpe_ratio, key_patterns, successful_strategies,
             failed_strategies, lessons, market_insights, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            summary.summary_id,
            summary.period_start.isoformat(),
            summary.period_end.isoformat(),
            summary.period_type,
            summary.total_cases,
            summary.total_trades,
            summary.win_rate,
            summary.avg_pnl,
            summary.sharpe_ratio,
            json.dumps(summary.key_patterns, ensure_ascii=False),
            json.dumps(summary.successful_strategies, ensure_ascii=False),
            json.dumps(summary.failed_strategies, ensure_ascii=False),
            json.dumps(summary.lessons, ensure_ascii=False),
            summary.market_insights,
            summary.created_at.isoformat(),
        ))

        conn.commit()

    def _calculate_stats(self, cases: List[TradingCase]) -> dict:
        """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
        total_cases = len(cases)

        # åªè®¡ç®—çœŸå®äº¤æ˜“ï¼ˆå¼€ä»“/å¹³ä»“ï¼‰ï¼Œä¸åŒ…æ‹¬æ­¢ç›ˆæ­¢æŸä¿®æ”¹
        real_trade_actions = {'open_long', 'open_short', 'close_position'}
        total_trades = 0

        for case in cases:
            if case.execution_result:
                for result in case.execution_result:
                    signal = result.get('signal', {})
                    # æ£€æŸ¥æ˜¯å¦ä¸ºçœŸå®äº¤æ˜“
                    if isinstance(signal, dict):
                        action = signal.get('action')
                    else:
                        action = getattr(signal, 'action', None)

                    if action in real_trade_actions:
                        total_trades += 1
                        break  # æ¯ä¸ªæ¡ˆä¾‹åªè®¡ç®—ä¸€æ¬¡

        pnls = [c.realized_pnl for c in cases if c.realized_pnl is not None]
        wins = len([p for p in pnls if p > 0])
        win_rate = wins / len(pnls) if pnls else 0.0
        avg_pnl = sum(pnls) / len(pnls) if pnls else 0.0

        # è®¡ç®—å¤æ™®æ¯”ç‡
        if len(pnls) >= 2:
            import numpy as np
            returns = np.array(pnls)
            mean_return = np.mean(returns)
            std_return = np.std(returns)
            sharpe_ratio = mean_return / std_return if std_return > 0 else 0.0
        else:
            sharpe_ratio = 0.0

        return {
            'total_cases': total_cases,
            'total_trades': total_trades,
            'win_rate': win_rate,
            'avg_pnl': avg_pnl,
            'sharpe_ratio': sharpe_ratio
        }

    async def _llm_summarize(self, cases: List[TradingCase], period_type: str, account_info: dict = None) -> Optional[str]:
        """ä½¿ç”¨LLMç”Ÿæˆæ‘˜è¦ï¼ˆå¯åŒ…å«è´¦æˆ·ä¿¡æ¯ï¼‰"""
        if not self.llm:
            return None

        # å‡†å¤‡æ¡ˆä¾‹æ•°æ®
        cases_text = self._prepare_cases_for_summary(cases)

        # å‡†å¤‡è´¦æˆ·ä¿¡æ¯æ–‡æœ¬
        account_text = ""
        if account_info:
            balance = account_info.get('balance', {})
            stats = account_info.get('statistics', {})
            positions = account_info.get('open_positions', [])

            account_text = f"""
## å½“å‰è´¦æˆ·çŠ¶æ€

- è´¦æˆ·ä½™é¢: ${balance.get('total', 0):.2f}
- å¯ç”¨èµ„é‡‘: ${balance.get('available', 0):.2f}
- å†»ç»“ä¿è¯é‡‘: ${balance.get('frozen', 0):.2f}
"""
            if stats:
                account_text += f"""- ç´¯è®¡å¹³ä»“æ¬¡æ•°: {stats.get('total_positions', 0)} æ¬¡
  - ç›ˆåˆ©æ¬¡æ•°: {stats.get('win_count', 0)} æ¬¡
  - äºæŸæ¬¡æ•°: {stats.get('loss_count', 0)} æ¬¡
  - èƒœç‡: {stats.get('win_rate', 0) * 100:.1f}%
- å·²å®ç°æ€»ç›ˆäº: ${stats.get('total_pnl', 0):.2f}
  - æœ€å¤§ç›ˆåˆ©: ${stats.get('max_profit', 0):.2f}
  - æœ€å¤§äºæŸ: ${stats.get('max_loss', 0):.2f}
"""
            if positions:
                unrealized_total = sum(float(p.get('unrealized_pnl', 0)) for p in positions)
                account_text += f"""- å½“å‰æŒä»“: {len(positions)} ä¸ª
- æœªå®ç°ç›ˆäº: ${unrealized_total:.2f}
"""

        prompt = f"""
è¯·å¯¹ä»¥ä¸‹{period_type}æœŸé—´çš„äº¤æ˜“æ¡ˆä¾‹è¿›è¡Œæ·±åº¦åˆ†æå’Œæ€»ç»“ã€‚

{account_text}

{cases_text}

è¯·ä»ä»¥ä¸‹è§’åº¦æä¾›æ‘˜è¦ï¼ˆä½¿ç”¨JSONæ ¼å¼ï¼‰ï¼š

1. **å…³é”®æ¨¡å¼** (key_patterns): åˆ—å‡º3-5ä¸ªå‘ç°çš„äº¤æ˜“æ¨¡å¼
2. **æˆåŠŸç­–ç•¥** (successful_strategies): åˆ—å‡ºæ•ˆæœå¥½çš„ç­–ç•¥ï¼ˆ2-3ä¸ªï¼‰
3. **å¤±è´¥ç­–ç•¥** (failed_strategies): åˆ—å‡ºéœ€è¦é¿å…çš„ç­–ç•¥ï¼ˆ2-3ä¸ªï¼‰
4. **æ ¸å¿ƒç»éªŒ** (lessons): æç‚¼3-5æ¡æœ€é‡è¦çš„ç»éªŒæ•™è®­
5. **å¸‚åœºæ´å¯Ÿ** (market_insights): ç”¨2-3å¥è¯æ€»ç»“è¿™æ®µæ—¶é—´çš„å¸‚åœºçŠ¶æ€

è¦æ±‚ï¼š
- ä¿æŒç®€æ´ï¼Œæ¯æ¡ä¸è¶…è¿‡50å­—
- ä¸“æ³¨äºå¯å¤ç”¨çš„æ¨¡å¼ï¼Œè€Œéå…·ä½“ç»†èŠ‚
- æå–æœ¬è´¨è§„å¾‹ï¼Œå¿½ç•¥å™ªéŸ³
- å¦‚æœæä¾›äº†è´¦æˆ·ä¿¡æ¯ï¼Œè¯·ç»“åˆè´¦æˆ·æ•´ä½“è¡¨ç°è¿›è¡Œåˆ†æ

è¾“å‡ºæ ¼å¼ï¼š
```json
{{
  "key_patterns": ["æ¨¡å¼1", "æ¨¡å¼2", ...],
  "successful_strategies": ["ç­–ç•¥1", "ç­–ç•¥2", ...],
  "failed_strategies": ["ç­–ç•¥1", "ç­–ç•¥2", ...],
  "lessons": ["ç»éªŒ1", "ç»éªŒ2", ...],
  "market_insights": "å¸‚åœºæ´å¯Ÿæ€»ç»“..."
}}
```
"""

        try:
            response = await self.llm.ainvoke([
                {"role": "user", "content": prompt}
            ])
            return response.content
        except Exception as e:
            print(f"âš ï¸  LLMæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def _prepare_cases_for_summary(self, cases: List[TradingCase]) -> str:
        """å‡†å¤‡æ¡ˆä¾‹æ•°æ®ä¾›LLMåˆ†æ"""
        lines = []

        for i, case in enumerate(cases[:20], 1):  # æœ€å¤š20ä¸ªæ¡ˆä¾‹
            lines.append(f"### æ¡ˆä¾‹ {i}")
            lines.append(f"æ—¶é—´: {case.timestamp.strftime('%Y-%m-%d %H:%M')}")

            # å†³ç­–
            if isinstance(case.decision, str):
                # æˆªå–å‰200å­—ç¬¦
                lines.append(f"åˆ†æ: {case.decision[:200]}...")

            # æ‰§è¡Œç»“æœ
            if case.execution_result:
                lines.append(f"æ‰§è¡Œ: {len(case.execution_result)} ä¸ªæ“ä½œ")

            # ç›ˆäº
            if case.realized_pnl is not None:
                result = "ç›ˆåˆ©" if case.realized_pnl > 0 else "äºæŸ"
                lines.append(f"ç»“æœ: {result} ${abs(case.realized_pnl):.2f}")

            # ç»éªŒ
            if case.lessons_learned:
                lines.append(f"ç»éªŒ: {', '.join(case.lessons_learned[:2])}")

            lines.append("")

        return "\n".join(lines)

    def _parse_summary_text(self, summary_text: str) -> dict:
        """è§£æLLMè¿”å›çš„æ‘˜è¦"""
        try:
            # æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'```json\n(.*?)\n```', summary_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # å°è¯•ç›´æ¥è§£æ
                json_str = summary_text

            data = json.loads(json_str)

            return {
                'key_patterns': data.get('key_patterns', []),
                'successful_strategies': data.get('successful_strategies', []),
                'failed_strategies': data.get('failed_strategies', []),
                'lessons': data.get('lessons', []),
                'market_insights': data.get('market_insights', ''),
            }
        except Exception as e:
            print(f"âš ï¸  è§£ææ‘˜è¦å¤±è´¥: {e}")
            return {
                'key_patterns': [],
                'successful_strategies': [],
                'failed_strategies': [],
                'lessons': [],
                'market_insights': summary_text[:200] if summary_text else '',
            }

    def _row_to_case(self, row: sqlite3.Row) -> TradingCase:
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸º TradingCase"""
        return TradingCase(
            case_id=row['case_id'],
            timestamp=datetime.fromisoformat(row['timestamp']),
            market_conditions=json.loads(row['market_conditions']),
            decision=row['decision'],
            execution_result=json.loads(row['execution_result']) if row['execution_result'] else None,
            realized_pnl=row['realized_pnl'],
            reflection=row['reflection'],
            lessons_learned=json.loads(row['lessons_learned']) if row['lessons_learned'] else None,
        )

    def _row_to_summary(self, row: sqlite3.Row) -> MemorySummary:
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸º MemorySummary"""
        return MemorySummary(
            summary_id=row['summary_id'],
            period_start=datetime.fromisoformat(row['period_start']),
            period_end=datetime.fromisoformat(row['period_end']),
            period_type=row['period_type'],
            total_cases=row['total_cases'],
            total_trades=row['total_trades'],
            win_rate=row['win_rate'],
            avg_pnl=row['avg_pnl'],
            sharpe_ratio=row['sharpe_ratio'],
            key_patterns=json.loads(row['key_patterns']),
            successful_strategies=json.loads(row['successful_strategies']),
            failed_strategies=json.loads(row['failed_strategies']),
            lessons=json.loads(row['lessons']),
            market_insights=row['market_insights'],
            created_at=datetime.fromisoformat(row['created_at']),
        )

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if hasattr(self._local, 'conn'):
            self._local.conn.close()
            delattr(self._local, 'conn')

    def __del__(self):
        """ææ„æ—¶å…³é—­è¿æ¥"""
        self.close()
