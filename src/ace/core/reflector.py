"""
Reflector - ACE åæ€è€…æ¨¡å—

èŒè´£ï¼š
1. åˆ†ææ‰§è¡Œç»“æœ
2. è¯Šæ–­å¤±è´¥åŸå› 
3. è¯„ä¼°ç­–ç•¥æœ‰æ•ˆæ€§
4. æå–æ–°æ´å¯Ÿ
"""

import json
from termcolor import cprint

from ..models import Reflection, ExecutionTrace, StrategyEvaluation, FailureType
from ..utils import PromptBuilder


class Reflector:
    """ACE åæ€è€…"""

    def __init__(self, llm):
        self.llm = llm

    async def reflect(self, trace: ExecutionTrace) -> Reflection:
        """å¯¹æ‰§è¡Œè½¨è¿¹è¿›è¡Œåæ€"""
        reflection = Reflection()
        reflection.trace_id = trace.trace_id

        try:
            # 1. æ„å»ºåæ€ Prompt
            prompt = PromptBuilder.build_reflector_prompt(trace)

            # 2. LLM åˆ†æ
            cprint("ğŸ¤” Reflector æ­£åœ¨åˆ†æ...", "magenta")
            response = await self.llm.ainvoke([
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªäº¤æ˜“åˆ†æä¸“å®¶ï¼Œè´Ÿè´£åæ€äº¤æ˜“å†³ç­–çš„è´¨é‡ã€‚"},
                {"role": "user", "content": prompt}
            ])

            reflection.reflection_text = response.content

            # 3. è§£æåæ€ç»“æœ
            parsed = self._parse_reflection(response.content)

            reflection.is_successful = parsed.get('is_successful', trace.execution_success)
            reflection.failure_type = FailureType(parsed.get('failure_type', 'none'))
            reflection.key_insights = parsed.get('key_insights', [])
            reflection.error_patterns = parsed.get('error_patterns', [])

            # 4. è¯„ä¼°ç­–ç•¥æœ‰æ•ˆæ€§
            for eval_data in parsed.get('strategy_evaluations', []):
                evaluation = StrategyEvaluation(
                    entry_id=eval_data.get('entry_id', ''),
                    is_helpful=eval_data.get('is_helpful', True),
                    reason=eval_data.get('reason', '')
                )
                reflection.strategy_evaluations.append(evaluation)

            # å¦‚æœ LLM æ²¡æœ‰è¯„ä¼°ç­–ç•¥ï¼Œä½¿ç”¨ç®€å•è§„åˆ™
            if not reflection.strategy_evaluations and trace.retrieved_entries:
                reflection.strategy_evaluations = self._simple_strategy_evaluation(trace)

            cprint(f"âœ… åæ€å®Œæˆ: æ´å¯Ÿ {len(reflection.key_insights)} ä¸ª, é”™è¯¯æ¨¡å¼ {len(reflection.error_patterns)} ä¸ª", "green")

        except Exception as e:
            cprint(f"âŒ Reflector å¤±è´¥: {e}", "red")
            # é™çº§ï¼šç®€å•çš„è§„åˆ™åˆ¤æ–­
            reflection.is_successful = trace.execution_success
            if not trace.execution_success:
                reflection.failure_type = FailureType.EXECUTION
                reflection.error_patterns = [f"æ‰§è¡Œå¤±è´¥: {trace.execution_error}"]

            # ç®€å•è¯„ä¼°ç­–ç•¥
            reflection.strategy_evaluations = self._simple_strategy_evaluation(trace)

        return reflection

    def _parse_reflection(self, llm_output: str) -> dict:
        """è§£æåæ€ JSON"""
        try:
            start = llm_output.find('{')
            end = llm_output.rfind('}') + 1

            if start >= 0 and end > start:
                json_str = llm_output[start:end]
                return json.loads(json_str)

        except Exception as e:
            cprint(f"âš ï¸  è§£æåæ€å¤±è´¥: {e}", "yellow")

        return {}

    def _simple_strategy_evaluation(self, trace: ExecutionTrace) -> list:
        """
        ç®€å•çš„ç­–ç•¥è¯„ä¼°ï¼ˆé™çº§æ–¹æ¡ˆï¼‰

        è§„åˆ™ï¼š
        - å¦‚æœæ‰§è¡ŒæˆåŠŸä¸”ç›ˆåˆ© â†’ æ‰€æœ‰ç­–ç•¥æ ‡è®°ä¸º helpful
        - å¦‚æœæ‰§è¡Œå¤±è´¥æˆ–äºæŸ â†’ æ‰€æœ‰ç­–ç•¥æ ‡è®°ä¸º harmful
        """
        evaluations = []

        if not trace.retrieved_entries:
            return evaluations

        # åˆ¤æ–­æ˜¯å¦æˆåŠŸ
        is_successful = trace.execution_success

        # å¦‚æœæœ‰ PnL ä¿¡æ¯ï¼Œä½¿ç”¨ç›ˆäºåˆ¤æ–­
        if trace.pnl is not None:
            is_successful = is_successful and (float(trace.pnl) >= 0)

        # åˆ›å»ºè¯„ä¼°
        for entry_id in trace.retrieved_entries[:5]:  # åªè¯„ä¼°å‰ 5 ä¸ª
            evaluations.append(StrategyEvaluation(
                entry_id=entry_id,
                is_helpful=is_successful,
                reason="åŸºäºæ‰§è¡Œç»“æœçš„ç®€å•è¯„ä¼°"
            ))

        return evaluations
